{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "with open('keyword_occurances.pkl','rb') as f:\n",
    "    mydata = pickle.load(f)\n",
    "    mydata = [map(int, x) for x in mydata]\n",
    "\n",
    "target = [m[10] for m in mydata]\n",
    "data = [j[:-1] for j in mydata]\n",
    "    \n",
    "inspire_X = np.asarray(data)\n",
    "inspire_y = np.asarray(target)\n",
    "inspire_y = inspire_y.ravel()\n",
    "\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(inspire_X))\n",
    "\n",
    "inspire_X_train = inspire_X[indices[:-160]]\n",
    "inspire_y_train = inspire_y[indices[:-160]]\n",
    "inspire_X_test  = inspire_X[indices[-160:]]\n",
    "inspire_y_test  = inspire_y[indices[-160:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(inspire_X_train, inspire_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(inspire_X_test)\n",
    "print pred\n",
    "#print inspire_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.mean( pred != inspire_y_test )\n",
    "print (1-error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTvec = clf.support_vectors_\n",
    "SUPPORT    = clf.support_\n",
    "nSUPPORT   = clf.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-class fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = svm.SVC(decision_function_shape='ovo')\n",
    "print clf1\n",
    "clf1.fit(inspire_X_train, inspire_y_train)\n",
    "pred1 = clf1.predict(inspire_X_test)\n",
    "error1 = np.mean( pred1 != inspire_y_test )\n",
    "print (1-error1)\n",
    "print pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print inspire_X_train.shape[1]\n",
    "dec = clf1.decision_function(inspire_X_test)\n",
    "#print dec\n",
    "\n",
    "print inspire_X_test[0]\n",
    "print dec[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have 3 classes, A, B and C // \n",
    "dec gives a number for [AB, AC, BC] // \n",
    "close to zero means more unsure if its a or b, a or c, etc // \n",
    "positive number means its A rather than B, negative its B over A for AB // \n",
    "so for dec[0] we have [B,C,B] // \n",
    "theres 2 B's and only 1 C // \n",
    "therefore, B is what is predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unbalanced problemos // an attempt to compensate for the lack of class 0 objects.. dont think its worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = svm.SVC(decision_function_shape='ovo', class_weight={0: 10})\n",
    "print clf2\n",
    "clf2.fit(inspire_X_train, inspire_y_train)\n",
    "pred2 = clf2.predict(inspire_X_test)\n",
    "error2 = np.mean( pred2 != inspire_y_test )\n",
    "print (1-error2)\n",
    "print pred1\n",
    "print inspire_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(decision_function_shape='ovo', )\n",
    "#svc = svm.SVC(C=1, kernel='linear')\n",
    "svc.fit(inspire_X_train, inspire_y_train).score(inspire_X_test, inspire_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "X = [\"a\", \"a\", \"b\", \"c\", \"c\", \"c\"]\n",
    "k_fold = KFold(n_splits=3)\n",
    "for train_indices, test_indices in k_fold.split(X):\n",
    "     print('Train: %s | test: %s' % (train_indices, test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[svc.fit(inspire_X[train], inspire_y[train]).score(inspire_X[test], inspire_y[test])\n",
    "         for train, test in k_fold.split(inspire_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(svc, inspire_X, inspire_y, cv=k_fold, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(svc, inspire_X, inspire_y, cv=k_fold, scoring='precision_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = inspire_X\n",
    "y = inspire_y\n",
    "\n",
    "#svc = svm.SVC(kernel='linear')\n",
    "svc = svm.SVC(decision_function_shape='ovo')\n",
    "\n",
    "C_s = np.logspace(-2, 1, 30)\n",
    "\n",
    "scores = list()\n",
    "scores_std = list()\n",
    "for C in C_s:\n",
    "    svc.C = C\n",
    "    this_scores = cross_val_score(svc, X, y, n_jobs=1)\n",
    "    scores.append(np.mean(this_scores))\n",
    "    scores_std.append(np.std(this_scores))\n",
    "\n",
    "# Do the plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "plt.semilogx(C_s, scores)\n",
    "plt.semilogx(C_s, np.array(scores) + np.array(scores_std), 'b--')\n",
    "plt.semilogx(C_s, np.array(scores) - np.array(scores_std), 'b--')\n",
    "locs, labels = plt.yticks()\n",
    "plt.yticks(locs, list(map(lambda x: \"%g\" % x, locs)))\n",
    "plt.ylabel('CV score')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylim(0.4, 0.55 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding a nice C! grid search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "Cs = np.logspace(-2, 1, 20)\n",
    "clf = GridSearchCV(estimator=svc, param_grid=dict(C=Cs), n_jobs=-1)\n",
    "\n",
    "clf.fit(inspire_X_train, inspire_y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print clf.best_score_ \n",
    "print clf.best_estimator_.C  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
