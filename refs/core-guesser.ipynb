{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrewblance/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from inspire_utils.record import get_value\n",
    "% matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename):\n",
    "    '''filename is a string= /path/to/file'''\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "def removeNonAscii(string):\n",
    "    return \"\".join( char for char in string if ord(char)<128 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(listing,which_version=0):\n",
    "    '''Get the title. If there are >1 versions, which_ver selects that version.'''\n",
    "    title = get_value(listing,\"extra_data.source_data.data.titles[%d].title\" % which_version)\n",
    "    title = removeNonAscii(title)\n",
    "    return title\n",
    "\n",
    "def get_abstract(listing,which_version=0):\n",
    "    #                             look at this location in \"example_api\"\n",
    "    abstract = get_value(listing,\"extra_data.source_data.data.abstracts[%d].value\" %which_version)\n",
    "    abstract = removeNonAscii(abstract)\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngrams(string, N=1):\n",
    "    tokens = nltk.word_tokenize(string)\n",
    "    ngram_tuples = list( ngrams(tokens,N) )\n",
    "    ngram_list = [''.join(words) for words in ngram_tuples]\n",
    "    return ngram_list\n",
    "\n",
    "def ngram_search(string,keywords):\n",
    "    ''' find the intersection of the ngram-ed string and the keyword list.'''\n",
    "    matches = list( set(string).intersection( set(keywords) ) )\n",
    "    return matches\n",
    "\n",
    "def eval_score(string, keywords, min_ngram=1,max_ngram=4):\n",
    "    scores = []\n",
    "    for N in range(min_ngram,max_ngram+1):\n",
    "        words = ngram_search( make_ngrams(string,N=N),keywords )\n",
    "     \n",
    "        scores.append(len(words))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keysfile = np.loadtxt(\"KeyWords.csv\", dtype=\"str\") # load the keywords.\n",
    "keywords = [word.lower() for word in keysfile]     # lowercase them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_list = pd.read_csv(\"./core_arxiv.txt\", names=[\"core\"])\n",
    "noncore_list = pd.read_csv(\"./noncore_arxiv.txt\", names=[\"noncore\"])\n",
    "core, noncore = [],[]\n",
    "\n",
    "# read the core arXiv list\n",
    "for line in core_list['core']:\n",
    "    name = line.split(\":\")[2]\n",
    "    core.append(name)\n",
    "core_list = core #pd.DataFrame(core, columns=[\"core\"])\n",
    "\n",
    "# read the noncore arXic list.\n",
    "for line in noncore_list['noncore']:\n",
    "    name = line.split(\":\")[2]\n",
    "    noncore.append(name)\n",
    "noncore_list = noncore #pd.DataFrame(noncore)\n",
    "\n",
    "inspire_core = set(np.genfromtxt(\"inspire_core.txt\").tolist())\n",
    "\n",
    "def get_coreness(listing,which_listing=0):\n",
    "    arXiv_id = get_value(listing,\"extra_data.source_data.data.arxiv_eprints[%d].value\" %which_listing)\n",
    "    if arXiv_id in core_list:\n",
    "        return 2\n",
    "    elif arXiv_id in noncore_list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_references(listing):\n",
    "    if get_value(listing, \"data.references\"):\n",
    "        refs = get_value(listing, \"data.references\")\n",
    "    else:\n",
    "        return [0.0,0.0]\n",
    "    \n",
    "    core_refs = 0.0\n",
    "    noncore_refs = 0.0\n",
    "    N_refs = float(len(refs))\n",
    "    for ref in refs:\n",
    "        if get_value(ref, \"record.$ref\"):\n",
    "            inspire_id = int(get_value(ref, \"record.$ref\").split(\"/\")[5])\n",
    "            if inspire_id in inspire_core:\n",
    "                core_refs = core_refs + 1.0\n",
    "            else:\n",
    "                noncore_refs = noncore_refs + 1.0\n",
    "    \n",
    "    f_core = core_refs/N_refs\n",
    "    f_noncore = noncore_refs/N_refs\n",
    "    \n",
    "    return [f_core, f_noncore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = [], []\n",
    "reference_fractions = []\n",
    "title_scores = []\n",
    "abstract_scores = []\n",
    "\n",
    "for listing in read_json(\"arXiv.json\"):\n",
    "    title = get_title(listing)\n",
    "    title_scores.append(eval_score(title, keywords))\n",
    "    \n",
    "    abstract = get_abstract(listing)\n",
    "    abstract_scores.append(eval_score(abstract, keywords) )\n",
    "    \n",
    "    text = ' '.join( ( title, abstract ) )\n",
    "    coreness = get_coreness(listing)\n",
    "    \n",
    "    f_refs = get_references(listing)\n",
    "\n",
    "    reference_fractions.append(f_refs)\n",
    "\n",
    "    texts.append(text)\n",
    "    labels.append(coreness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_scores = np.asarray(title_scores)\n",
    "a_scores = np.asarray(abstract_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-51395d67e171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m38774\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_fractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "T = np.asarray(texts)\n",
    "T = T.reshape(38774,1)\n",
    "\n",
    "R = np.asarray(reference_fractions)\n",
    "\n",
    "L = np.asarray(labels)\n",
    "L = L.reshape(38774,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFS = np.concatenate((T, t_scores), axis=1)\n",
    "REF_ = np.concatenate((REFS, a_scores), axis=1)\n",
    "REF__ = np.concatenate((REF_, R), axis=1)\n",
    "REF = np.concatenate((REF__, L), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Title-sing</th>\n",
       "      <th>Title-bi</th>\n",
       "      <th>Title-tri</th>\n",
       "      <th>Title-quad</th>\n",
       "      <th>Abs-sing</th>\n",
       "      <th>Abs-bi</th>\n",
       "      <th>Abs-tri</th>\n",
       "      <th>Abs-quad</th>\n",
       "      <th>core refs</th>\n",
       "      <th>non-core refs</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28184</th>\n",
       "      <td>Mott Quantum Criticality in the Anisotropic 2D...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6456</th>\n",
       "      <td>Balanced Reed-Solomon Codes We consider the pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10183</th>\n",
       "      <td>Fermion Dipole Moment and Holography In the ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.93617</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535</th>\n",
       "      <td>Quantization conditions and functional equatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92500</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36703</th>\n",
       "      <td>Resonances in the continuum, field induced non...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Title-sing Title-bi  \\\n",
       "28184  Mott Quantum Criticality in the Anisotropic 2D...          0        0   \n",
       "6456   Balanced Reed-Solomon Codes We consider the pr...          0        0   \n",
       "10183  Fermion Dipole Moment and Holography In the ba...          0        0   \n",
       "4535   Quantization conditions and functional equatio...          0        0   \n",
       "36703  Resonances in the continuum, field induced non...          2        0   \n",
       "\n",
       "      Title-tri Title-quad Abs-sing Abs-bi Abs-tri Abs-quad  core refs  \\\n",
       "28184         0          0        9      0       0        0    0.00000   \n",
       "6456          0          0       11      1       0        0    0.00000   \n",
       "10183         0          0        9      2       0        0    0.93617   \n",
       "4535          0          0        9      1       0        0    0.92500   \n",
       "36703         0          0        6      0       0        0    0.00000   \n",
       "\n",
       "       non-core refs  Result  \n",
       "28184        0.50000       0  \n",
       "6456         0.00000       0  \n",
       "10183        0.00000       2  \n",
       "4535         0.02500       2  \n",
       "36703        0.04386       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = ['Text', 'Title-sing', 'Title-bi', 'Title-tri', 'Title-quad', 'Abs-sing','Abs-bi', 'Abs-tri', 'Abs-quad','core refs', 'non-core refs', 'Result']\n",
    "REF= pd.DataFrame(REF, columns=keys)\n",
    "REF = REF.reindex(np.random.permutation(REF.index))\n",
    "\n",
    "REF['Result'] =REF['Result'].astype(int)\n",
    "\n",
    "keysPC = ['core refs', 'non-core refs']\n",
    "REF[keysPC] =REF[keysPC].astype(float)\n",
    "\n",
    "REF['Text'] =REF['Text'].astype(str)\n",
    "REF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF.to_pickle('REFS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
