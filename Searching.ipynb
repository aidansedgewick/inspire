{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Incoming Enteries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    entries = []\n",
    "    for i in range(len(text)):\n",
    "        text_split = re.split(\"ENDTITLES|ENDTITLE|ENDABSTRACTS\",text[i])\n",
    "        title1 = text_split[0].strip()\n",
    "        title2 = text_split[1].strip()\n",
    "        abstract = text_split[2].replace(\"\\r\\n\",\" \").strip()\n",
    "        decision = text_split[3].strip()\n",
    "        entries.append({u'title':title1,u'abstract':abstract,u'decision':decision})\n",
    "    return(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIGRAMS(string):\n",
    "    token = nltk.word_tokenize(string)\n",
    "    bigram = ngrams(token,2)\n",
    "    bigrams = ', '.join(' '.join((a, b)) for a, b in bigram)\n",
    "    biNoSpace = bigrams.replace(\" \",\"\")\n",
    "    BIGRAM = biNoSpace.replace(\",\", \" \")\n",
    "    return BIGRAM\n",
    "    \n",
    "def TRIGRAMS(string):\n",
    "    token = nltk.word_tokenize(string)\n",
    "    trigram = ngrams(token, 3)\n",
    "    trigrams = ', '.join(' '.join((a, b, c)) for a, b, c in trigram)\n",
    "    triNoSpace = trigrams.replace(\" \",\"\")\n",
    "    TRIGRAM = triNoSpace.replace(\",\", \" \")\n",
    "    return TRIGRAM\n",
    "\n",
    "def QUADGRAMS(string):\n",
    "    token = nltk.word_tokenize(string)\n",
    "    quadgram = ngrams(token, 4)\n",
    "    quadgrams = ', '.join(' '.join((a, b, c, d)) for a, b, c, d in quadgram)\n",
    "    quadNoSpace = quadgrams.replace(\" \",\"\")\n",
    "    QUADGRAM = quadNoSpace.replace(\",\", \" \")  \n",
    "    return QUADGRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load any csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(name):\n",
    "    with open(name+\".csv\", \"rb\") as f:\n",
    "        File = np.loadtxt(f, dtype=str)\n",
    "    return File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ListOfWords = []\n",
    "def Search(Abs, W):\n",
    "    match = set(Abs).intersection(set(W))\n",
    "    Match = list(match)\n",
    "    i=0\n",
    "    while (i < len(Match)):\n",
    "        ListOfWords.append(Match[i])\n",
    "        #print Match[i]\n",
    "        i = i + 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thing to tie it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Key_Num(TEXT, DICT):\n",
    "    Search(TEXT.split()             ,DICT)\n",
    "    Search(BIGRAMS(TEXT).split()    ,DICT)\n",
    "    Search(TRIGRAMS(TEXT).split()   ,DICT)\n",
    "    Search(QUADGRAMS(TEXT).split()  ,DICT)\n",
    "\n",
    "    score = (len(ListOfWords))\n",
    "    #print(\"The amount of terms found is {0}\" .format(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Cellular Higgs non-nonlinear network model of microbial fuel cellENDTITLECellular non-nonlinear network model of microbial fuel cell ENDTITLES A cellular non-linear network (CNN) is a uniform regular array of locally\\r\\nconnected continuous-state machines, or nodes, which update their states\\r\\nsimultaneously in discrete time. A microbial fuel cell (MFC) is an\\r\\nelectro-chemical reactor using the metabolism of bacteria to drive an\\r\\nelectrical current. In a CNN model of the MFC, each node takes a vector of\\r\\nstates which represent geometrical characteristics of the cell, like the\\r\\nelectrodes or impermeable borders, and quantify measurable properties like\\r\\nbacterial population, charges produced and hydrogen ions concentrations. The\\r\\nmodel allows the study of integral reaction of the MFC, including temporal\\r\\noutputs, to spatial disturbances of the bacterial population and supply of\\r\\nnutrients. The model can also be used to evaluate inhomogeneous configurations\\r\\nof bacterial populations attached on the electrode biofilms. ENDABSTRACTS Rejected\"\n",
    "text1 = [text1]\n",
    "TEXT     = split_text(text1)\n",
    "TITLE    = TEXT[0].get('title')\n",
    "ABSTRACT = TEXT[0].get('abstract')\n",
    "DECISION = TEXT[0].get('decision')\n",
    "\n",
    "key = load(\"KeyWords\")\n",
    "q=0\n",
    "while (q < len(key)):\n",
    "    key[q] = key[q].lower()\n",
    "    q = q + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 7, 'Rejected']\n"
     ]
    }
   ],
   "source": [
    "RESULTS = [] \n",
    "RESULTS.append(Key_Num(TITLE, key))\n",
    "ListOfWords = []\n",
    "RESULTS.append(Key_Num(ABSTRACT, key))\n",
    "RESULTS.append(DECISION)\n",
    "\n",
    "print RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My program took 1.23861718178 to run\n"
     ]
    }
   ],
   "source": [
    "print \"My program took\", time.time() - start_time, \"to run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
